{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c9549f",
   "metadata": {},
   "source": [
    "##                       Building AI Tools for News Summarization and Personal Productivity Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48bd7a",
   "metadata": {},
   "source": [
    "#### Task1 : News Article Summarizer - Recursive Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8551f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the input text using RecursiveCharacterTextSplitter:\n",
      "\n",
      "chunk 1: 'Helping every dang soul': Beloved camp director was among those lost in Texas flooding\n",
      "\n",
      "chunk 2: Jane Ragsdale spent her summers by the Guadalupe, the very river that killed her a\n",
      "\n",
      "chunk 3: very river that killed her a week ago today in the catastrophic July Fourth flood. Mention her name\n",
      "\n",
      "chunk 4: flood. Mention her name in Kerrville, Texas, this week, and folks tend to do two things: tear up\n",
      "\n",
      "chunk 5: to do two things: tear up and smile. \"I mean I can't tell you how many people, acquaintances of\n",
      "\n",
      "chunk 6: many people, acquaintances of mine say, 'My dear, dear friend died.' And then they said, 'Did you\n",
      "\n",
      "chunk 7: And then they said, 'Did you know Jane Ragsdale?' and I say, 'Yeah, I did,' \" said Karen Taylor,\n",
      "\n",
      "chunk 8: I did,' \" said Karen Taylor, who lives in nearby Hunt, Texas. For her, Ragsdale was West Kerr\n",
      "\n",
      "chunk 9: her, Ragsdale was West Kerr County personified. \"Everybody's friendly here, but she embodied that\n",
      "\n",
      "chunk 10: here, but she embodied that friendliness and generosity and love for others. I just can't imagine\n",
      "\n",
      "chunk 11: others. I just can't imagine life without her,\" Taylor said. Ragsdale, who was in her late 60s, did\n",
      "\n",
      "chunk 12: who was in her late 60s, did a lot of things, but she's best known as the owner and director of\n",
      "\n",
      "chunk 13: as the owner and director of Heart O' the Hills camp for girls. She was born into the business.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Take the article text from the website and perform Text Splitter Techniques on the input text.\n",
    "\n",
    "# Step-1: Input_Text\n",
    "input_text = ''' 'Helping every dang soul': Beloved camp director was among those lost in Texas flooding \n",
    "                 Jane Ragsdale spent her summers by the Guadalupe, the very river that killed her a week ago today in the catastrophic July Fourth flood. Mention her name in Kerrville, Texas, this week, and folks tend to do two things: tear up and smile. \"I mean I can't tell you how many people, acquaintances of mine say, 'My dear, dear friend died.' And then they said, 'Did you know Jane Ragsdale?' and I say, 'Yeah, I did,' \" said Karen Taylor, who lives in nearby Hunt, Texas. For her, Ragsdale was West Kerr County personified. \"Everybody's friendly here, but she embodied that friendliness and generosity and love for others. I just can't imagine life without her,\" Taylor said. Ragsdale, who was in her late 60s, did a lot of things, but she's best known as the owner and director of Heart O' the Hills camp for girls. She was born into the business.'''\n",
    "\n",
    "# Step-2: Importing the necessary libraries for text splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# Step-3: Initialize the RecursiveCharacterTextSplitter\n",
    "text_splitter1 = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=30)\n",
    "\n",
    "# Step-4: Split the input text using the RecursiveCharacterTextSplitter\n",
    "split_text1 = text_splitter1.split_text(input_text)\n",
    "\n",
    "# Step-5: Print the results of the text splitting using RecursiveCharacterTextSplitter\n",
    "print(\"Splitting the input text using RecursiveCharacterTextSplitter:\\n\")\n",
    "for i,chunk in enumerate(split_text1) :\n",
    "    print(f\"chunk {i+1}: {chunk}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f549f",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "-> input_text = ''' ... '''\n",
    "\n",
    "🟢 Purpose: This defines a news article-style input as a string.\n",
    "\n",
    "   -> We are simulating a real news article to test text splitting.\n",
    "\n",
    "-> from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "🟢 Purpose: We import two different text splitter classes from langchain_text_splitters.\n",
    "\n",
    "   -> These are used to break long texts into smaller, manageable chunks, which is essential for:\n",
    "      -> Better summarization\n",
    "      -> Efficient use of LLMs (since input size is limited)\n",
    "\n",
    "-> text_splitter1 = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=30)\n",
    "\n",
    "🟢 Purpose: We are creating an instance of the RecursiveCharacterTextSplitter.\n",
    "\n",
    "   -> chunk_size=100: Each chunk will have up to 100 characters.\n",
    "   -> chunk_overlap=30: Each chunk overlaps the previous one by 30 characters (to maintain context continuity).\n",
    "   -> Recursive splitting tries to split smartly — e.g., at sentence boundaries, paragraphs, etc.\n",
    "\n",
    "-> split_text1 = text_splitter1.split_text(input_text)\n",
    "\n",
    "🟢 Purpose: This takes our input_text and breaks it into chunks using the recursive method.\n",
    "\n",
    "   -> split_text1 is now a list of strings (each one is a chunk).\n",
    "\n",
    "-> print(\"Splitting the input text using RecursiveCharacterTextSplitter:\\n\")\n",
    "for i,chunk in enumerate(split_text1) :\n",
    "    print(f\"chunk {i+1}: {chunk}\\n\")\n",
    "    \n",
    "🟢 Purpose: Neatly prints each chunk for review.\n",
    "\n",
    "   -> Helps you visually evaluate:\n",
    "      -> Are chunks readable?\n",
    "      -> Do they break mid-sentence or maintain clarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f77e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the input text using CharacterTextSplitter:\n",
      "\n",
      "chunk 1: 'Helping every dang soul': Beloved camp director was among those lost in Texas flooding \n",
      "                 Jane Ragsdale spent her summers by the Guadalupe, the very river that killed her a week ago today in the catastrophic July Fourth flood. Mention her name in Kerrville, Texas, this week, and folks tend to do two things: tear up and smile. \"I mean I can't tell you how many people, acquaintances of mine say, 'My dear, dear friend died.' And then they said, 'Did you know Jane Ragsdale?' and I say, 'Yeah, I did,' \" said Karen Taylor, who lives in nearby Hunt, Texas. For her, Ragsdale was West Kerr County personified. \"Everybody's friendly here, but she embodied that friendliness and generosity and love for others. I just can't imagine life without her,\" Taylor said. Ragsdale, who was in her late 60s, did a lot of things, but she's best known as the owner and director of Heart O' the Hills camp for girls. She was born into the business.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step-1: Importing the necessary libraries for text splitting\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Step-2: Initialize the CharacterTextSplitter\n",
    "text_splitter2 = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "\n",
    "# Step-3: Split the input text using CharacterTextSplitter\n",
    "split_text2 = text_splitter2.split_text(input_text)\n",
    "\n",
    "# Step-4: Print the results of the text splitting using CharacterTextSplitter\n",
    "print(\"Splitting the input text using CharacterTextSplitter:\\n\")\n",
    "for i,chunk in enumerate(split_text2) :\n",
    "    print(f\"chunk {i+1}: {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176749c",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "-> text_splitter2 = CharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "\n",
    "🟢 Purpose: Now using the simpler CharacterTextSplitter, which splits purely by character count — no sentence/structure awareness.\n",
    "\n",
    "   -> Larger chunk size (300) to show difference.\n",
    "\n",
    "-> split_text2 = text_splitter2.split_text(input_text)\n",
    "\n",
    "🟢 Purpose: Same as before, but with basic character-based splitting. Less intelligent — might cut mid-sentence.\n",
    "\n",
    "-> print(\"Splitting the input text using CharacterTextSplitter:\\n\")\n",
    "for i,chunk in enumerate(split_text2) :\n",
    "    print(f\"chunk {i+1}: {chunk}\\n\")\n",
    "\n",
    "🟢 Purpose: Shows the output of the second splitting method, so we can compare results with the first one.\n",
    "\n",
    "#### Comparison Between RecursiveCharacterTextSplitter and CharacterTextSplitter\n",
    "\n",
    "   -> RecursiveCharacterTextSplitter : attempts to break text on logical boundaries like punctuation and sentence ends.  \n",
    "   -> Result: Smaller, more natural chunks; ideal for summarization tasks.\n",
    "\n",
    "   -> CharacterTextSplitter : cuts strictly by character length without considering sentence structure.  \n",
    "   -> Result: Fewer chunks, but may split in awkward places.\n",
    "\n",
    "### Conclusion:\n",
    "RecursiveCharacterTextSplitter produced more human-readable chunks for this article. It is better suited when the goal is to preserve sentence meaning and improve summarization quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70359182",
   "metadata": {},
   "source": [
    "#### Task-2 : Meeting Transcript Section Extractor - HTML Header Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the input HTML using HTMLHeaderTextSplitter:\n",
      "\n",
      "HTML chunk 1: page_content='Board Meeting' metadata={'header h1': 'Board Meeting'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 2: page_content='Company updates and revenue discussion.' metadata={'header h1': 'Board Meeting'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 3: page_content='Marketing' metadata={'header h1': 'Board Meeting', 'header h2': 'Marketing'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 4: page_content='Campaign performance reports.' metadata={'header h1': 'Board Meeting', 'header h2': 'Marketing'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 5: page_content='Finance' metadata={'header h1': 'Board Meeting', 'header h2': 'Finance'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 6: page_content='Financial projections for Q3.' metadata={'header h1': 'Board Meeting', 'header h2': 'Finance'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 7: page_content='Q&A Session' metadata={'header h1': 'Board Meeting', 'header h2': 'Finance', 'header h3': 'Q&A Session'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HTML chunk 8: page_content='Open questions from board members.' metadata={'header h1': 'Board Meeting', 'header h2': 'Finance', 'header h3': 'Q&A Session'}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# step-1: importing the necessary libraries for text splitting\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "# Step-2: Input HTML content\n",
    "input_html ='''\n",
    "<h1>Board Meeting</h1>\n",
    " <p>Company updates and revenue discussion.</p>\n",
    " <h2>Marketing</h2>\n",
    " <p>Campaign performance reports.</p>\n",
    " <h2>Finance</h2>\n",
    " <p>Financial projections for Q3.</p>\n",
    " <h3>Q&A Session</h3>\n",
    " <p>Open questions from board members.</p>\n",
    " '''\n",
    " \n",
    "header_to_split_on = [\n",
    "    (\"h1\", \"header h1\"),\n",
    "    (\"h2\", \"header h2\"),\n",
    "    (\"h3\", \"header h3\"),\n",
    "    (\"h4\", \"header h4\"),\n",
    "    (\"h5\", \"header h5\"),\n",
    "    (\"h6\", \"header h6\")\n",
    "]\n",
    "\n",
    "# Step-3: Initialize the HTMLHeaderTextSplitter\n",
    "html_splitter = HTMLHeaderTextSplitter(\n",
    "    header_to_split_on)\n",
    "\n",
    "# Step-4: Split the input HTML using HTMLHeaderTextSplitter\n",
    "split_html = html_splitter.split_text(input_html)\n",
    "\n",
    "# Step-5: Print the results of the text splitting using HTMLHeaderTextSplitter\n",
    "print(\"Splitting the input HTML using HTMLHeaderTextSplitter:\\n\")\n",
    "for i, chunk in enumerate(split_html):\n",
    "    print(f\"HTML chunk {i+1}: {chunk}\\n\")\n",
    "    print(\"-\"*150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505791e",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "-> We imported the `HTMLHeaderTextSplitter` from LangChain's text splitter library.  \n",
    "   -> This class is used to **break structured HTML documents into sections** based on header tags (`<h1>`, `<h2>`, etc.).\n",
    "\n",
    "-> input_html:\n",
    "   -> We defined a sample HTML transcript of a board meeting. \n",
    "      -> Paragraphs under each heading\n",
    "-> This is the type of structured HTML the splitter is designed to work with.\n",
    "\n",
    "-> header_to_split_on:\n",
    "   -> This is a **mapping** that tells the splitter which HTML header tags to use for splitting.  \n",
    "      -> Each tuple means:  \n",
    "      ->`\"h1\"` → treat as `\"header h1\"` in the output metadata.\n",
    "\n",
    "-> Initialize the HTMLHeaderTextSplitter\n",
    "   -> html_splitter = HTMLHeaderTextSplitter(header_to_split_on)\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "   -> Creates a html_splitter object using the heading rules we defined.\n",
    "   -> This splitter will now know how to break the input HTML into structured document chunks.\n",
    "\n",
    "-> split_html = html_splitter.split_text(input_html)\n",
    "\n",
    "🟢 Purpose:  \n",
    "\n",
    "   -> Actually performs the **splitting operation**.  \n",
    "   -> Returns a list of LangChain `Document` objects, each with:\n",
    "   ->  `.page_content`: The content chunk\n",
    "   ->  `.metadata`: The header tag info (e.g., which `h1`/`h2` it belongs to)\n",
    "\n",
    "-> Print the results of the text splitting using HTMLHeaderTextSplitter\n",
    "print(\"Splitting the input HTML using HTMLHeaderTextSplitter:\\n\")\n",
    "for i, chunk in enumerate(split_html):\n",
    "    print(f\"HTML chunk {i+1}: {chunk}\\n\")\n",
    "    print(\"-\"*150)\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "   -> Loops through the split results and prints them neatly.\n",
    "   -> Helps us to verify that the text was correctly split into meaningful meeting sections (e.g., \"Marketing\", \"Finance\", etc.).\n",
    "\n",
    "## 📝 Observation:\n",
    "\n",
    "-> The HTMLHeaderTextSplitter successfully extracted meaningful sections such as:\n",
    "   -> Board Meeting\n",
    "   ->  Marketing\n",
    "   -> Finance\n",
    "   -> Q&A Session\n",
    "-> This method is useful for processing structured meeting transcripts from HTML files, making it easier to summarize or analyze individual sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a8e44",
   "metadata": {},
   "source": [
    "### Task-3 : Daily Productivity Prompter - OpenAI API Integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Suggest 3 study tasks for a student who has 2 hours today.\n",
      "Response:\n",
      "Here are three study tasks that a student can complete in 2 hours:\n",
      "\n",
      "**Task 1: Review Notes (30 minutes)**\n",
      "Review your class notes from the past week or two. Go through each page, summarize the key points in your own words, and make sure you understand the concepts. This will help you reinforce your learning and identify areas where you need more practice or review.\n",
      "\n",
      "**Task 2: Practice Problems (45 minutes)**\n",
      "Choose a topic or subject that you're currently studying and practice solving problems or past exams. This will help you apply what you've learned and build your problem-solving skills. Try to complete as many problems as you can within the time frame, and check your answers to see where you need to improve.\n",
      "\n",
      "**Task 3: Flashcard Creation and Review (45 minutes)**\n",
      "Create flashcards for key terms, concepts, or formulas in your subject. Write the term or question on one side and the definition or answer on the other. Then, quiz yourself by covering the answer side and trying to recall the information. This will help you memorize important details and reinforce your understanding of the material.\n",
      "\n",
      "Remember, you can adjust the time allocated to each task based on your needs and preferences. Take short breaks if you need to, and stay focused to make the most of your 2-hour study session!\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Prompt: prepare an exam study plan for a student in a small paragrapgh.\n",
      "Response:\n",
      "To prepare for an exam, create a study plan by setting specific goals and deadlines. Start by reviewing the exam syllabus and making a list of key topics to focus on. Allocate dedicated study time each day, breaking it down into manageable chunks, such as 2-3 hours per session. Prioritize the most challenging topics and create a schedule to review notes, practice problems, and past exams. Set milestones and track progress, allowing time for revision and practice before the exam date. Additionally, take regular breaks to avoid burnout and stay motivated by rewarding yourself for reaching study milestones.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Prompt: Give me a morning routine to stay productive in a small paragraph.\n",
      "Response:\n",
      "To stay productive, start your morning with a consistent routine. Begin by waking up 30 minutes earlier than usual and drinking a full glass of water to rehydrate after a night of sleep. Next, spend 10-15 minutes meditating or practicing deep breathing exercises to clear your mind. Then, write down your top three priorities for the day in a journal or planner, and make a to-do list to help you stay focused. Finally, get some natural light by taking a short walk outside or opening your curtains, and fuel up with a healthy breakfast to give you energy and motivation to tackle the day ahead.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Prompt: Suggest a beginner-griendly fitness plan in a small paragraph.\n",
      "Response:\n",
      "For a beginner-friendly fitness plan, start with short and manageable sessions, 2-3 times a week. Begin with 10-15 minute brisk walks or light cardio exercises, such as jogging in place or jumping jacks. Gradually incorporate bodyweight exercises like push-ups, squats, and lunges, aiming for 3 sets of 5-8 reps. As you build endurance, increase the duration and intensity of your workouts. You can also try following along with free online fitness videos or mobile apps that offer guided routines and tracking features to help you stay motivated and on track. Remember to listen to your body and rest when needed, and don't forget to stretch before and after each workout to prevent injury.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step-1: Importing the necessary libraries for OpenAI API integration\n",
    "from openai import OpenAI\n",
    "\n",
    "# Step-2: Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Step-3: Import os\n",
    "import os\n",
    "\n",
    "# Step-4: Initialize the OpenAI client with API key and base URL\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=\"https://api.sambanova.ai/v1\"\n",
    ")\n",
    "\n",
    "# Step-5: Prompt the OpenAI API with various tasks\n",
    "# Here are some example prompts to test the OpenAI API\n",
    "prompts = [\n",
    "    \"Suggest 3 study tasks for a student who has 2 hours today.\",\n",
    "    \"prepare an exam study plan for a student in a small paragraph.\",\n",
    "    \"Give me a morning routine to stay productive in a small paragraph.\",\n",
    "    \"Suggest a beginner-friendly fitness plan in a small paragraph.\",\n",
    "]\n",
    "\n",
    "# Step-6: Function to generate response from OpenAI API\n",
    "def generate_response(prompt):\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"Meta-Llama-3.3-70B-Instruct\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        print(f\"Response:\\n{response.choices[0].message.content}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        \n",
    "    print(\"-\" * 150)\n",
    "\n",
    "# Step-7: Call the function for each prompt\n",
    "for prompt in prompts:\n",
    "    generate_response(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eff879",
   "metadata": {},
   "source": [
    "### Code Explanation:\n",
    "\n",
    "-> from openai import OpenAI\n",
    "\n",
    "🟢 Purpose:  \n",
    "\n",
    "Imports the `OpenAI` class from the `openai` library.  \n",
    "We are using it to make API calls to the SambaNova-hosted OpenAI-compatible endpoint.\n",
    "\n",
    "-> Load environment variables from .env file\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "Loads our .env file, which contains environment variables like your API key.\n",
    "This avoids hardcoding credentials directly in the script — good for security.\n",
    "\n",
    "-> import os\n",
    "\n",
    "🟢 Purpose:  \n",
    "\n",
    "   -> `os` is used to access environment variables (e.g., `os.getenv(\"API_KEY\")`) loaded from `.env`.\n",
    "\n",
    "->  Initialize the OpenAI client with API key and base URL\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "   -> Creates a client instance of OpenAI using:\n",
    "   -> Our secret API key (retrieved securely)\n",
    "   -> A custom base URL (sambanova.ai) — not OpenAI’s default URL\n",
    "   -> This is essential to send requests to SambaNova's hosted LLMs (e.g., Llama3).\n",
    "\n",
    "-> prompts\n",
    "\n",
    "🟢 Purpose:  \n",
    "\n",
    "This is a list of input prompts we want the model to answer.  \n",
    "Each prompt represents a **personal productivity request**, just as the assignment requires.\n",
    "\n",
    "->  Function to generate response from OpenAI API : def generate_response(prompt):\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "Defines a function that takes a prompt, sends it to the OpenAI model, and prints the response.\n",
    "\n",
    "-> chat completions:\n",
    "Uses the chat completions endpoint to get a response from the Meta Llama 3 model.\n",
    "It uses the standard chat format with a system/user conversation.\n",
    "\n",
    "-> print(f\"Response:\\n{response.choices[0].message.content}\")\n",
    "\n",
    "🟢 Purpose:  \n",
    "\n",
    "Prints the model’s generated text (only the actual message content from the first choice).\n",
    "\n",
    "-> Exception:\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "Catches any exceptions (e.g., rate limits, connection errors) so our program won’t crash and you'll know what went wrong.\n",
    "\n",
    "-> Call the function for each prompt\n",
    "for prompt in prompts:\n",
    "    generate_response(prompt)\n",
    "\n",
    "🟢 Purpose:\n",
    "\n",
    "Iterates through our list of prompts, calls the API for each, and prints the results.\n",
    "\n",
    "## 🧠 Observation:\n",
    "\n",
    "The OpenAI API (via SambaNova) successfully generated responses for various personal productivity prompts such as study plans, morning routines, and fitness suggestions. The chat format allowed dynamic interaction, and the outputs were human-like and helpful. This approach is useful for building productivity tools that offer contextual advice to users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
